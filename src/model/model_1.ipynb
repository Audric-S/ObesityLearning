{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.calibration import LinearSVC\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier, OutputCodeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# charger les donn√©es\n",
    "df=pd.read_csv('../data/new_dataset.csv')\n",
    "\n",
    "def get_classification_score(dataset, list_of_features, label, model):\n",
    "    temp = dataset.copy()   \n",
    "    y = temp.pop(label)\n",
    "    \n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(temp, y,test_size=0.25, random_state=0)\n",
    "\n",
    "    # Xtrain = Xtrain[list_of_features].values\n",
    "    # Xtest = Xtest[list_of_features].values\n",
    "        \n",
    "    if len(Xtrain.shape) < 2:\n",
    "        Xtrain = Xtrain.reshape(-1, 1)\n",
    "        \n",
    "    if len(Xtest.shape) < 2:\n",
    "        Xtest = Xtest.reshape(-1, 1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    Xtrain = scaler.fit_transform(Xtrain)\n",
    "    Xtest = scaler.transform(Xtest)\n",
    "        \n",
    "    model.fit(Xtrain,ytrain)\n",
    "\n",
    "    ypredit = model.predict(Xtest)\n",
    "\n",
    "    # disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    #     model,\n",
    "    #     Xtest,\n",
    "    #     ytest,\n",
    "    #     display_labels=y.unique(),\n",
    "    #     cmap=plt.cm.Blues,\n",
    "    # )\n",
    "\n",
    "    # print(disp.confusion_matrix)\n",
    "    # plt.show()\n",
    "    \n",
    "    # print(classification_report(ytest, ypredit))\n",
    "    # print(confusion_matrix(ytest, ypredit))\n",
    "    return accuracy_score(ytest, ypredit)\n",
    "\n",
    "# Name model\n",
    "tree = DecisionTreeClassifier(random_state=5, criterion='entropy')\n",
    "ovo_tree = OneVsOneClassifier(tree)\n",
    "ovr_tree = OneVsRestClassifier(tree)\n",
    "ecoc = OutputCodeClassifier(tree, code_size=2)\n",
    "\n",
    "# Feature scaling\n",
    "\n",
    "linear_svc = LinearSVC(\n",
    "    multi_class='ovr', \n",
    "    dual=False, \n",
    "    max_iter=15000,\n",
    "    C=12)\n",
    "\n",
    "# param_grid = {\"max_depth\": [3, 5, 8]}\n",
    "# tree_optimized = GridSearchCV(tree, param_grid=param_grid, cv=3)\n",
    "# ovo_tree = OneVsOneClassifier(tree_optimized)\n",
    "# ovr_tree = OneVsRestClassifier(tree_optimized)\n",
    "# ecoc = OutputCodeClassifier(tree_optimized, code_size=2)\n",
    "\n",
    "print(get_classification_score(df, \"\", \"NObeyesdad\", tree))\n",
    "# print(get_classification_score(df, \"\", \"NObeyesdad\", ovo_tree))\n",
    "# print(get_classification_score(df, \"\", \"NObeyesdad\", ovr_tree))\n",
    "# print(get_classification_score(df, \"\", \"NObeyesdad\", ecoc))\n",
    "# print(get_classification_score(df, \"\", \"NObeyesdad\", model))\n",
    "\n",
    "def generate_random_features_list(all_features, max_features=-1):\n",
    "    if max_features == -1:\n",
    "        return all_features\n",
    "    n_features = np.random.randint(1, max_features+1)\n",
    "    return np.random.choice(all_features, size=n_features, replace=False)\n",
    "\n",
    "all_features = [\"Weight\", \"Height\", \"Gender\", \"Age\", \"family_history_with_overweight\",\n",
    "                    \"FAVC\", \"FCVC\", \"NCP\", \"CAEC\", \"SMOKE\", \"CH2O\", \"SCC\", \"FAF\", \"TUE\",\n",
    "                    \"CALC\", \"MTRANS\"]\n",
    "\n",
    "tab_score = []\n",
    "tab_feature = []\n",
    "\n",
    "for i in range(30):\n",
    "    features = generate_random_features_list(all_features, len(all_features))\n",
    "    score = get_classification_score(df, features, \"NObeyesdad\", linear_svc)\n",
    "    tab_score.append(score)\n",
    "    tab_feature.append(features)\n",
    "    # print(f\"{features} : {score}\")\n",
    "\n",
    "# print(tab_score)\n",
    "\n",
    "tab_score = []\n",
    "tab_feature = []\n",
    "\n",
    "for i in range(30):\n",
    "    features = generate_random_features_list(all_features, len(all_features))\n",
    "    score = get_classification_score(df, features, \"NObeyesdad\", tree)\n",
    "    tab_score.append(score)\n",
    "    tab_feature.append(features)\n",
    "    # print(f\"{features} : {score}\")\n",
    "\n",
    "# for i in range(10):\n",
    "#     print(tab_score[i], \" avec les features suivantes : \", tab_feature[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
